#!/usr/bin/env bash

# Paths
URL_FILE="$HOME/Documents/Notes/downloads.md"
DOWNLOAD_DIR="$HOME/Downloads/"
DOWNLOADED_FILE="$HOME/Downloads/downloaded_links.txt"
LOG_FILE="$HOME/Downloads/download.log"

# Ensure folders exist
mkdir -p "$DOWNLOAD_DIR"
mkdir -p "$(dirname "$DOWNLOADED_FILE")"
touch "$URL_FILE"
touch "$DOWNLOADED_FILE"
touch "$LOG_FILE"

# Max parallel downloads
MAX_PARALLEL=3

# Check if link already downloaded
is_link_downloaded() {
    grep -qxF "$1" "$DOWNLOADED_FILE"
}

# Notification helpers
notify_success() { notify-send --expire-time=5000 "Download completed" "$1"; }
notify_error() { notify-send --expire-time=5000 "Download failed" "$1"; }

# Function to download a link (runs in background)
download_link() {
    url="$1"
    [ -z "$url" ] && return  # skip empty links

    if is_link_downloaded "$url"; then
        notify-send --expire-time=5000 "Already downloaded" "$url"
        return
    fi

    # Detect type
    if echo "$url" | grep -qE 'youtube\.com|youtu\.be|vimeo\.com|dailymotion\.com'; then
        type="Embedded video"
    else
        type="File"
    fi

    # Predict filename
    if [ "$type" = "Embedded video" ]; then
        filename=$(yt-dlp --get-filename -o "%(title)s.%(ext)s" "$url" 2>/dev/null | head -1)
        [ -z "$filename" ] && filename="unknown.mp4"
    else
        filename=$(basename "${url%%\?*}")
        [ -z "$filename" ] && filename="download"
    fi

    # Download depending on type
    case "$type" in
        "Embedded video")
            if yt-dlp -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' \
                      --merge-output-format mp4 \
                      --external-downloader aria2c \
                      --external-downloader-args 'aria2c:-x2 -s2' \
                      -o "$DOWNLOAD_DIR/$filename" \
                      "$url" >> "$LOG_FILE" 2>&1; then
                notify_success "$filename"
            else
                notify_error "$url"
            fi
            ;;
        *)
            if aria2c --check-certificate=false -x2 -s2 -d "$DOWNLOAD_DIR" -o "$filename" "$url" >> "$LOG_FILE" 2>&1; then
                notify_success "$filename"
            else
                notify_error "$filename"
            fi
            ;;
    esac

    # Record as downloaded
    echo "$url" >> "$DOWNLOADED_FILE"
}

# Wrapper to respect MAX_PARALLEL
run_with_limit() {
    # Wait until less than MAX_PARALLEL jobs running
    while [ "$(jobs -rp | wc -l)" -ge "$MAX_PARALLEL" ]; do
        sleep 1
    done
    download_link "$1" &
}

# Function to process URLs from a file
process_file() {
    while IFS= read -r url; do
        [[ -z "$url" || "$url" =~ ^# ]] && continue
        run_with_limit "$url"
    done < "$URL_FILE"
    wait  # Wait for all background jobs to finish
}

# Initial run: process URLs from the file
process_file

# Clipboard watcher (X11)
old_clipboard=""
while true; do
    new_clipboard=$(xclip -o -selection clipboard 2>/dev/null)
    if [ "$new_clipboard" != "$old_clipboard" ]; then
        for url in $(echo "$new_clipboard" | grep -Eo 'https?://[^ ]+'); do
            run_with_limit "$url"
        done
        old_clipboard="$new_clipboard"
    fi
    sleep 1
done
