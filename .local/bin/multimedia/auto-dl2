#!/usr/bin/env bash

# Paths
URL_FILE="$HOME/Documents/Notes/downloads.md"
DOWNLOAD_DIR="$HOME/Downloads/"
DOWNLOADED_FILE="$HOME/Downloads/downloaded_links.txt"
LOG_FILE="$HOME/Downloads/download.log"

# Ensure folders exist
mkdir -p "$DOWNLOAD_DIR"
mkdir -p "$(dirname "$DOWNLOADED_FILE")"
touch "$URL_FILE" "$DOWNLOADED_FILE" "$LOG_FILE"

# Max parallel downloads
MAX_PARALLEL=3

# Logging helper
log() {
    ts="$(date '+%Y-%m-%d %H:%M:%S')"
    echo "[$ts] $*" | tee -a "$LOG_FILE"
}

# Check if link already downloaded
is_link_downloaded() {
    grep -qxF "$1" "$DOWNLOADED_FILE"
}

# Notification helpers
notify_success() { notify-send --expire-time=5000 "Download completed" "$1"; }
notify_error() { notify-send --expire-time=5000 "Download failed" "$1"; }

# Function to download a link (runs in background)
download_link() {
    url="$1"
    [ -z "$url" ] && return

    if is_link_downloaded "$url"; then
        log "‚ö†Ô∏è Already downloaded: $url"
        notify-send --expire-time=5000 "Already downloaded" "$url"
        return
    fi

    log "‚¨áÔ∏è Starting download: $url"

    # Detect type
    if echo "$url" | grep -qE 'youtube\.com|youtu\.be|vimeo\.com|dailymotion\.com'; then
        type="Embedded video"
    else
        type="File"
    fi

    # Predict filename
    if [ "$type" = "Embedded video" ]; then
        filename=$(yt-dlp --get-filename -o "%(title)s.%(ext)s" "$url" 2>/dev/null | head -1)
        [ -z "$filename" ] && filename="unknown.mp4"
    else
        filename=$(basename "${url%%\?*}")
        [ -z "$filename" ] && filename="download"
    fi

    # Download depending on type
    case "$type" in
        "Embedded video")
            if yt-dlp -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' \
                      --merge-output-format mp4 \
                      --external-downloader aria2c \
                      --external-downloader-args 'aria2c:-x2 -s2' \
                      -o "$DOWNLOAD_DIR/$filename" \
                      "$url" >> "$LOG_FILE" 2>&1; then
                log "‚úÖ Download completed: $filename"
                notify_success "$filename"
            else
                log "‚ùå Download failed: $url"
                notify_error "$url"
            fi
            ;;
        *)
            if aria2c --check-certificate=false -x2 -s2 -d "$DOWNLOAD_DIR" -o "$filename" "$url" >> "$LOG_FILE" 2>&1; then
                log "‚úÖ Download completed: $filename"
                notify_success "$filename"
            else
                log "‚ùå Download failed: $url"
                notify_error "$filename"
            fi
            ;;
    esac

    echo "$url" >> "$DOWNLOADED_FILE"
}

# Wrapper to respect MAX_PARALLEL
run_with_limit() {
    while [ "$(jobs -rp | wc -l)" -ge "$MAX_PARALLEL" ]; do
        sleep 1
    done
    download_link "$1" &
}

# Function to process URLs from a file
process_file() {
    while IFS= read -r url; do
        [[ -z "$url" || "$url" =~ ^# ]] && continue
        run_with_limit "$url"
    done < "$URL_FILE"
    wait
}

# Initial run: process URLs from the file
process_file

# --- Clipboard watcher (X11 + Wayland) ---
old_clipboard=""
while true; do
    if [ -n "$WAYLAND_DISPLAY" ] && command -v wl-paste >/dev/null 2>&1; then
        new_clipboard=$(wl-paste 2>/dev/null)
    elif [ -n "$DISPLAY" ] && command -v xclip >/dev/null 2>&1; then
        new_clipboard=$(xclip -o -selection clipboard 2>/dev/null)
    else
        log "‚ùå No compatible clipboard tool found (wl-paste or xclip required)"
        exit 1
    fi

    if [ "$new_clipboard" != "$old_clipboard" ]; then
        log "üìã Clipboard changed: ${new_clipboard:0:100}..."
        echo "$new_clipboard" | grep -Eo 'https?://[^ ]+' | while read -r url; do
            log "üîó Detected URL: $url"
            run_with_limit "$url"
        done
        old_clipboard="$new_clipboard"
    fi
    sleep 1
done
